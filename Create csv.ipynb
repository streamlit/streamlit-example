{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv files\n",
    "transactions = pd.read_csv(\"data/transactions_train.csv\",parse_dates = ['t_dat'])\n",
    "articles = pd.read_csv(\"data/articles.csv\")\n",
    "customers = pd.read_csv(\"data/customers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of articles, number of customers and total volume change over the time\n",
    "\n",
    "# aggregate the transaction by date\n",
    "transaction_aggr = transactions.groupby(['t_dat']).nunique().reset_index()[['t_dat','customer_id','article_id']]\n",
    "\n",
    "# create a column showing sum per user per day\n",
    "transaction_aggr['sum'] = transactions.groupby(['t_dat']).sum().reset_index()[['price']]\n",
    "transaction_aggr = transaction_aggr.rename(columns={\"customer_id\": \"nr_customer\",\n",
    "                                                   \"article_id\":\"nr_article\",\n",
    "                                                   \"sum\":\"total_volume\"})\n",
    "\n",
    "# Save csv\n",
    "transaction_aggr.to_csv(\"data/transaction_aggr.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colors\n",
    "\n",
    "# join transaction dataset with articles\n",
    "transaction_article_colour = pd.merge(transactions[['article_id', 't_dat']], articles[['article_id', 'colour_group_name']], how = 'inner', on = ['article_id']).reset_index()\n",
    "\n",
    "# colours articles by month\n",
    "articles_transaction_color_aggr = transaction_article_colour.groupby(['t_dat','colour_group_name']).count().reset_index()[['t_dat','colour_group_name','article_id']]\n",
    "articles_transaction_color_aggr['t_dat'] = pd.to_datetime(articles_transaction_color_aggr['t_dat'])\n",
    "\n",
    "# Convert date into month and year\n",
    "articles_transaction_color_aggr['month_year']=articles_transaction_color_aggr['t_dat'].dt.strftime('%m/%Y')\n",
    "articles_transaction_color_aggr['year']= pd.DatetimeIndex(articles_transaction_color_aggr['t_dat']).year\n",
    "\n",
    "# Save csv\n",
    "articles_transaction_color_aggr.to_csv(\"data/articles_transaction_color_aggr.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the month of each date\n",
    "transactions['month'] =  pd.DatetimeIndex(transactions['t_dat']).month\n",
    "\n",
    "# Define the seasons along the year\n",
    "transactions.loc[(transactions[\"month\"] >= 3) & (transactions[\"month\"] <= 5) , \"season\"] = \"Spring\"\n",
    "transactions.loc[(transactions[\"month\"] >= 6) & (transactions[\"month\"] <= 8) , \"season\"] = \"Summer\"\n",
    "transactions.loc[(transactions[\"month\"] >= 9) & (transactions[\"month\"] <= 11) , \"season\"] = \"Autumn\"\n",
    "transactions.loc[(transactions[\"month\"] == 12) , \"season\"] = \"Winter\"\n",
    "transactions.loc[(transactions[\"month\"] >= 1) & (transactions[\"month\"] <= 2) , \"season\"] = \"Winter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Products per season\n",
    "transactions_season = transactions[['season' , 'article_id']].merge(articles[['article_id' , 'product_type_name' , 'product_type_no']] , on = 'article_id').groupby(['season' , 'product_type_no' ,'product_type_name']).agg({'product_type_no': 'count'}).rename(columns={'product_type_no': 'quantity'}).reset_index()\n",
    "\n",
    "# Save csv\n",
    "transactions_season.to_csv(\"data/transactions_season.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age Group\n",
    "import numpy as np\n",
    "bins = np.array([0,15,19,35,50,99])\n",
    "labels = ['unknown' , 'teens' , 'young' , 'middle-aged' , 'old']\n",
    "customers['age_cat'] = pd.cut(customers['age'], bins=bins, labels=labels, include_lowest=True)\n",
    "customers_age = customers[['customer_id' , 'age_cat']].merge(transactions[['customer_id' , 'season']] , on = 'customer_id').groupby(['season' , 'age_cat']).agg({'age_cat': 'count'}).rename(columns={'age_cat': 'quantity'}).reset_index()\n",
    "\n",
    "# Save csv\n",
    "customers_age.to_csv(\"data/customers_age.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colors per season\n",
    "colors_season = transactions[['season' , 'article_id']].merge(articles[['article_id' , 'perceived_colour_master_name']] , on = 'article_id').groupby(['season' , 'perceived_colour_master_name']).agg({'perceived_colour_master_name': 'count'}).rename(columns={'perceived_colour_master_name': 'quantity'}).reset_index()\n",
    "# Save csv\n",
    "colors_season.to_csv(\"data/colors_season.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Product recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Items bought by customer_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_agg_customer = transactions.groupby('customer_id')['article_id'].apply(list).reset_index(name='articles')\n",
    "\n",
    "# Save csv\n",
    "transactions_agg_customer.to_csv(\"data/transactions_agg_customer.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>articles</th>\n",
       "      <th>count_articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...</td>\n",
       "      <td>[568601043]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>[794321007]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000757967448a6cb83efb3ea7a3fb9d418ac7adf2379d...</td>\n",
       "      <td>[448509014, 719530003]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000172a9c322560c849754ffbdfdb2180d408aa7176b94...</td>\n",
       "      <td>[685814001, 685814001, 685814001]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d44dbe7f6c4b35200abdb052c77a87596fe1bdcc37...</td>\n",
       "      <td>[923134003, 835801001, 923134005, 865929003, 5...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189505</th>\n",
       "      <td>fffd0248a95c2e49fee876ff93598e2e20839e51b9b767...</td>\n",
       "      <td>[509091057, 859737002, 573085028, 926745002, 8...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189506</th>\n",
       "      <td>fffd870c6324ad3bda24e4d6aeae221c199479086bfdfd...</td>\n",
       "      <td>[750423010, 761269001]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189507</th>\n",
       "      <td>fffef3b6b73545df065b521e19f64bf6fe93bfd450ab20...</td>\n",
       "      <td>[748269009, 803757023, 881919001, 748269009, 9...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189508</th>\n",
       "      <td>ffffbbf78b6eaac697a8a5dfbfd2bfa8113ee5b403e474...</td>\n",
       "      <td>[713997002, 557599022, 804992033, 791587007, 7...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189509</th>\n",
       "      <td>ffffcf35913a0bee60e8741cb2b4e78b8a98ee5ff2e6a1...</td>\n",
       "      <td>[689365050, 762846027, 794819001, 884081001]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189510 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              customer_id  \\\n",
       "0       00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...   \n",
       "1       000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...   \n",
       "2       0000757967448a6cb83efb3ea7a3fb9d418ac7adf2379d...   \n",
       "3       000172a9c322560c849754ffbdfdb2180d408aa7176b94...   \n",
       "4       0001d44dbe7f6c4b35200abdb052c77a87596fe1bdcc37...   \n",
       "...                                                   ...   \n",
       "189505  fffd0248a95c2e49fee876ff93598e2e20839e51b9b767...   \n",
       "189506  fffd870c6324ad3bda24e4d6aeae221c199479086bfdfd...   \n",
       "189507  fffef3b6b73545df065b521e19f64bf6fe93bfd450ab20...   \n",
       "189508  ffffbbf78b6eaac697a8a5dfbfd2bfa8113ee5b403e474...   \n",
       "189509  ffffcf35913a0bee60e8741cb2b4e78b8a98ee5ff2e6a1...   \n",
       "\n",
       "                                                 articles  count_articles  \n",
       "0                                             [568601043]               1  \n",
       "1                                             [794321007]               1  \n",
       "2                                  [448509014, 719530003]               2  \n",
       "3                       [685814001, 685814001, 685814001]               3  \n",
       "4       [923134003, 835801001, 923134005, 865929003, 5...              10  \n",
       "...                                                   ...             ...  \n",
       "189505  [509091057, 859737002, 573085028, 926745002, 8...               6  \n",
       "189506                             [750423010, 761269001]               2  \n",
       "189507  [748269009, 803757023, 881919001, 748269009, 9...              11  \n",
       "189508  [713997002, 557599022, 804992033, 791587007, 7...               6  \n",
       "189509       [689365050, 762846027, 794819001, 884081001]               4  \n",
       "\n",
       "[189510 rows x 3 columns]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_agg_customer['count_articles']=transactions_agg_customer['articles'].apply(lambda x: len(x))\n",
    "transactions_agg_customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_agg_customer=transactions_agg_customer[transactions_agg_customer['count_articles']> 12].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>articles</th>\n",
       "      <th>count_articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00077dbd5c4a4991e092e63893ccf29294a9d5c46e8501...</td>\n",
       "      <td>[867966009, 935892001, 907149001, 918171001, 9...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fb6e772c5d0023892065e659963da90b1866035558e...</td>\n",
       "      <td>[831684001, 871519008, 871519008, 871519008, 9...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00357b192b81fc83261a45be87f5f3d59112db7d117513...</td>\n",
       "      <td>[904961001, 880815006, 804916006, 880815006, 8...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00465ec96dd32dca19f85108cbce142de6667a7ace8208...</td>\n",
       "      <td>[566140001, 862103001, 784247009, 559601019, 8...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>004d932f7a27ac3167c77db81d9cfd89392729e7f7e0d4...</td>\n",
       "      <td>[678942001, 678942058, 678942047, 783346028, 7...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8979</th>\n",
       "      <td>ffef8aec5cf011fa1393b40337a5993ce0b7b81af6b322...</td>\n",
       "      <td>[840909001, 762028005, 789769001, 879139002, 8...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8980</th>\n",
       "      <td>fff03ab4ca865dbe1a56bb32a8e41ea23e1b4dfcc4a13f...</td>\n",
       "      <td>[772902001, 901813001, 907409001, 759814009, 9...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8981</th>\n",
       "      <td>fff187d1386edced8ef49b1df0155241943c9c4cc7abbf...</td>\n",
       "      <td>[867966010, 892558001, 706016003, 914441002, 9...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8982</th>\n",
       "      <td>fff2282977442e327b45d8c89afde25617d00124d0f999...</td>\n",
       "      <td>[919786001, 891322004, 759054001, 891322004, 8...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8983</th>\n",
       "      <td>fff3573d9131d15da6a46c1ca8f03b5d37e4f6b804171e...</td>\n",
       "      <td>[783517006, 813298001, 873279001, 914805006, 6...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8984 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            customer_id  \\\n",
       "0     00077dbd5c4a4991e092e63893ccf29294a9d5c46e8501...   \n",
       "1     000fb6e772c5d0023892065e659963da90b1866035558e...   \n",
       "2     00357b192b81fc83261a45be87f5f3d59112db7d117513...   \n",
       "3     00465ec96dd32dca19f85108cbce142de6667a7ace8208...   \n",
       "4     004d932f7a27ac3167c77db81d9cfd89392729e7f7e0d4...   \n",
       "...                                                 ...   \n",
       "8979  ffef8aec5cf011fa1393b40337a5993ce0b7b81af6b322...   \n",
       "8980  fff03ab4ca865dbe1a56bb32a8e41ea23e1b4dfcc4a13f...   \n",
       "8981  fff187d1386edced8ef49b1df0155241943c9c4cc7abbf...   \n",
       "8982  fff2282977442e327b45d8c89afde25617d00124d0f999...   \n",
       "8983  fff3573d9131d15da6a46c1ca8f03b5d37e4f6b804171e...   \n",
       "\n",
       "                                               articles  count_articles  \n",
       "0     [867966009, 935892001, 907149001, 918171001, 9...              18  \n",
       "1     [831684001, 871519008, 871519008, 871519008, 9...              20  \n",
       "2     [904961001, 880815006, 804916006, 880815006, 8...              14  \n",
       "3     [566140001, 862103001, 784247009, 559601019, 8...              14  \n",
       "4     [678942001, 678942058, 678942047, 783346028, 7...              18  \n",
       "...                                                 ...             ...  \n",
       "8979  [840909001, 762028005, 789769001, 879139002, 8...              13  \n",
       "8980  [772902001, 901813001, 907409001, 759814009, 9...              13  \n",
       "8981  [867966010, 892558001, 706016003, 914441002, 9...              13  \n",
       "8982  [919786001, 891322004, 759054001, 891322004, 8...              22  \n",
       "8983  [783517006, 813298001, 873279001, 914805006, 6...              18  \n",
       "\n",
       "[8984 rows x 3 columns]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_agg_customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8e0e166ba96a7d4e2fa83ebe7fed15d07c87011085831e4f221b5c2ce14faf93']"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(transactions_agg_customer.iloc[[5000]]['customer_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_MONTHS = 1\n",
    "\n",
    "window = relativedelta(months=N_MONTHS)\n",
    "last_date = transactions['t_dat'].max()\n",
    "\n",
    "threshold = last_date - window\n",
    "\n",
    "mask = transactions['t_dat'] > threshold\n",
    "transactions_baseline = transactions[mask]\n",
    "\n",
    "purchase_dict = {} # Dict that contains each article the user bought and the count of times it was bought\n",
    "\n",
    "for x in zip(transactions['customer_id'], transactions['article_id']):\n",
    "    cust_id, art_id = x\n",
    "    \n",
    "    if cust_id not in purchase_dict:\n",
    "        purchase_dict[cust_id] = {}\n",
    "    purchase_dict[cust_id][art_id] = purchase_dict[cust_id].get(art_id, 0) + 1\n",
    "    \n",
    "# List of the most bought articles for all users\n",
    "best_ever = list(transactions['article_id'].value_counts().index)\n",
    "\n",
    "# Save\n",
    "import pickle\n",
    "f = open(\"data/best_ever.pkl\", \"wb\")\n",
    "pickle.dump(best_ever, f)\n",
    "f.close()\n",
    "\n",
    "f = open(\"data/purchase_dict.pkl\", \"wb\")\n",
    "pickle.dump(purchase_dict, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(189510, 26252)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "\n",
    "# Get the transactions from September 1, 2020 on\n",
    "transactions_copy = transactions.copy()\n",
    "transactions = transactions_copy[transactions_copy['t_dat'] > '2020-08-31'].sort_values(by=['customer_id'])\n",
    "\n",
    "# Count the number of same articles bought by the same person and convert to dataframe\n",
    "counts_df = transactions.groupby(['t_dat', 'customer_id', 'article_id', 'price', 'sales_channel_id']).size()\n",
    "counts_df = counts_df.to_frame()\n",
    "counts_df.reset_index(inplace=True)\n",
    "small_counts = counts_df.rename(columns={0: 'count'})\n",
    "\n",
    "# Transactions file after September 1, 2020 while the number of same articles bought by each person\n",
    "small_counts = small_counts.sort_values('customer_id')\n",
    "\n",
    "from scipy.sparse import csr_matrix, dok_matrix\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "# Auxiliary function\n",
    "def to_dense(array):\n",
    "    \"\"\"\n",
    "    Converts a spare matrix (where a lot of elements are zero) to a dense \n",
    "    array (an array where the elements are all sequential starting at index 0). \n",
    "    \n",
    "    :param array: Matrix to be converted\n",
    "    :return: Dense array\n",
    "    \"\"\"\n",
    "    try:\n",
    "        array = array.todense()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return np.array(array).squeeze()\n",
    "\n",
    "# Create sparse matrix user-item \n",
    "def build_counts_table(df):\n",
    "    \"\"\"\n",
    "    Gives an sparse matrix where the columns and the items and the rows the customer. \n",
    "    The value is the number of times that a customer has bought an item. \n",
    "    \n",
    "    :param df: original dataframe with transactions\n",
    "    :return: \n",
    "        * Sparse matrix\n",
    "        * Customer ids corresponding to each row\n",
    "        * Items ids corresponding to each column\n",
    "    \"\"\"\n",
    "    # Get customer ids and item ids\n",
    "    customer_ids = CategoricalDtype(sorted(df.customer_id.unique()), ordered=True)\n",
    "    item_ids = CategoricalDtype(sorted(df.article_id.unique()), ordered=True)\n",
    "\n",
    "    # Get sparse matrix\n",
    "    row = df.customer_id.astype(customer_ids).cat.codes\n",
    "    col = df.article_id.astype(item_ids).cat.codes\n",
    "    sparse_matrix = csr_matrix((df[\"count\"], (row, col)), \\\n",
    "                           shape=(customer_ids.categories.size, item_ids.categories.size))\n",
    "\n",
    "    return sparse_matrix, customer_ids, item_ids\n",
    "\n",
    "# Get sparse matrix for the transactions from Sept 1, 2020\n",
    "counts, indexes, columns = build_counts_table(small_counts)\n",
    "\n",
    "# Number of rows is number of customers, number of columns is number of articles\n",
    "print(counts.shape)\n",
    "\n",
    "# Get the ids of the top n customers\n",
    "def top_active_customers(counts, indexes, columns, n):\n",
    "    \"\"\"\n",
    "    Returns the id of the top n customers, in terms of items bought \n",
    "    \n",
    "    :param counts, indexes, columns: Tuple returned by build_counts_table\n",
    "    :param n: Number of users\n",
    "    :return: Series of customerID of the top users\n",
    "    \"\"\"\n",
    "    # Operate with the sparse matrix, convert to dense the result\n",
    "    sums = to_dense(counts.sum(axis=1))\n",
    "    # Get indices\n",
    "    indices = sums.argsort()\n",
    "    return indexes.categories[indices[-n:]]\n",
    "\n",
    "# Get the ids of the top n articles\n",
    "def top_bought_articles(counts, indexes, columns, n):\n",
    "    \"\"\"\n",
    "    Returns the top n most bought items\n",
    "    \n",
    "    :param counts, indexes, columns: Tuple returned by build_counts_table\n",
    "    :param n: Number of items\n",
    "    :return: Series of itemID of the top items\n",
    "    \"\"\"\n",
    "    # Operate with the sparse matrix, convert to dense the result\n",
    "    sums = to_dense(counts.sum(axis=0))\n",
    "    # Get indices\n",
    "    indices = sums.argsort()\n",
    "    return columns.categories[indices[-n:]]\n",
    "\n",
    "# Get the top 5,000 articles and users from the transactions after Sept 1, 2020\n",
    "top_customers = top_active_customers(counts, indexes, columns, 5000)\n",
    "top_items = top_bought_articles(counts, indexes, columns, 5000)\n",
    "\n",
    "# Transactions from Sept 1, 2020\n",
    "s = small_counts.copy()\n",
    "# Transactions from Sept 1, 2020 that include one of the most bought 5,000 items\n",
    "s = s[s.article_id.isin(top_items)]\n",
    "\n",
    "# Transactions from Sept 1, 2020 that include one of the most bought 5,000 items and belong to one of the most active 5,000 customers\n",
    "s = s[s.customer_id.isin(top_customers)]\n",
    "\n",
    "# Drop the non-relevant info\n",
    "s = s.drop(s.columns[[0, 3, 4]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Creation of the matrix\n",
    "X_transactions_matrix = pd.pivot_table(s,values='count',index='customer_id',columns='article_id')\n",
    "# We fill Na values with 0\n",
    "X_transactions_matrix = X_transactions_matrix.fillna(0)\n",
    "\n",
    "# Merge with interesting columns from items dataset\n",
    "X_transactions = s.merge(articles[['article_id','colour_group_code','index_group_name','product_group_name']],on=['article_id'])\n",
    "X_transactions.head()\n",
    "\n",
    "product_cat = X_transactions[['article_id','colour_group_code','index_group_name','product_group_name']].drop_duplicates('article_id')\n",
    "product_cat = product_cat.sort_values(by='article_id')\n",
    "\n",
    "# First, for the numerical feature 'colour_group_code' we create an euclidian matrix based on euclidean distances between items\n",
    "color_cat_matrix = np.reciprocal(euclidean_distances(np.array(product_cat['colour_group_code']).reshape(-1,1))+1)\n",
    "euclidean_matrix = pd.DataFrame(color_cat_matrix,columns=product_cat['article_id'],index=product_cat['article_id'])\n",
    "\n",
    "# Then, for the categorical feature 'product_group_name' we construct a cosinus similarity matrix\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "doc_term = tfidf_vectorizer.fit_transform(list(product_cat['product_group_name']))\n",
    "dt_matrix = pd.DataFrame(doc_term.toarray().round(3), index=[i for i in product_cat['article_id']], columns=tfidf_vectorizer.get_feature_names_out())\n",
    "cos_similar_matrix = pd.DataFrame(cosine_similarity(dt_matrix.values),columns=product_cat['article_id'],index=product_cat['article_id'])\n",
    "\n",
    "# Then, for the categorical feature 'index_group_name' we also construct a cosinus similarity matrix\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "doc_term = tfidf_vectorizer.fit_transform(list(product_cat['index_group_name']))\n",
    "dt_matrix1 = pd.DataFrame(doc_term.toarray().round(3), index=[i for i in product_cat['article_id']], columns=tfidf_vectorizer.get_feature_names_out())\n",
    "dt_matrix1 = dt_matrix1 + 0.01\n",
    "cos_similar_matrix1 = pd.DataFrame(cosine_similarity(dt_matrix1.values),columns=product_cat['article_id'],index=product_cat['article_id'])\n",
    "\n",
    "# Finally, by multiplying the following three matrices we obtain our final Item-Item Similarity Matrix\n",
    "similar_matrix = cos_similar_matrix.multiply(euclidean_matrix).multiply(cos_similar_matrix1)\n",
    "\n",
    "content_matrix = X_transactions_matrix.dot(similar_matrix)\n",
    "# We then normalize the obtained matrix\n",
    "std = MinMaxScaler(feature_range=(0, 1))\n",
    "std.fit(content_matrix.values)\n",
    "content_matrix = std.transform(content_matrix.values)\n",
    "\n",
    "# We then create a table with the predicted_count for each couple (customer_id, article_id)\n",
    "content_matrix = pd.DataFrame(content_matrix,columns=sorted(X_transactions['article_id'].unique()),index=sorted(X_transactions['customer_id'].unique()))\n",
    "# The trained User-Item Matrix is then re-converted back into a data frame\n",
    "content_df = content_matrix.stack().reset_index()\n",
    "content_df = content_df.rename(columns={'level_0':'customer_id','level_1':'article_id',0:'predicted_count'})\n",
    "\n",
    "# Save csv\n",
    "content_df.to_csv(\"data/content_df.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rule-based algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-137-f53c0c021f62>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Recent_transactions['customer_id']=Recent_transactions['customer_id'].apply(lambda x: int(x[-16:], 16))\n"
     ]
    }
   ],
   "source": [
    "Recent_transactions=transactions[['t_dat','customer_id','article_id']]\n",
    "last_ts = Recent_transactions['t_dat'].max()\n",
    "# we then convert the customer_id to int\n",
    "Recent_transactions['customer_id']=Recent_transactions['customer_id'].apply(lambda x: int(x[-16:], 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-138-654d1fcf31e2>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Recent_transactions['ldbw'] = tmp['ldbw'].values\n"
     ]
    }
   ],
   "source": [
    "# We create a temporary dataframe with the last day of the week for each date\n",
    "tmp = Recent_transactions[['t_dat']].copy()\n",
    "# We get the day of week for each date : Monday = 0, Tuesday = 1 and so on\n",
    "tmp['dow'] = tmp['t_dat'].dt.dayofweek\n",
    "# We truncated t_dat into the Tuesday of t_dat week and we save it as ldbw\n",
    "tmp['ldbw'] = tmp['t_dat'] - pd.TimedeltaIndex(tmp['dow'] - 1, unit='D')\n",
    "# For t_dat from Wednesday until Sunday we add 7 days to get next Tuesday, do nothing for t_dat Monday and Tuesdaytmp.loc[tmp['dow'] >=2 , 'ldbw'] = tmp.loc[tmp['dow'] >=2 , 'ldbw'] + pd.TimedeltaIndex(np.ones(len(tmp.loc[tmp['dow'] >=2])) * 7, unit='D')\n",
    "Recent_transactions['ldbw'] = tmp['ldbw'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_sales = Recent_transactions.drop('customer_id', axis=1).groupby(['ldbw', 'article_id']).count().reset_index()\n",
    "weekly_sales = weekly_sales.rename(columns={'t_dat': 'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We then merge it with our transaction dataset\n",
    "Recent_transactions = Recent_transactions.merge(weekly_sales, on=['ldbw', 'article_id'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_sales = weekly_sales.reset_index().set_index('article_id')\n",
    "\n",
    "# We create the \"count_targ\" column corresponding to the number of transactions during the last week\n",
    "Recent_transactions = Recent_transactions.merge(\n",
    "    weekly_sales.loc[weekly_sales['ldbw']==last_ts, ['count']],\n",
    "    on='article_id', suffixes=(\"\", \"_targ\"))\n",
    "\n",
    "# We then fill the missing values with 0\n",
    "Recent_transactions['count_targ'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "Recent_transactions['quotient'] = Recent_transactions['count_targ'] / Recent_transactions['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of articles to be recommended by customer_id\n",
    "N=12\n",
    "\n",
    "# We group the quotient column by article_id and we then rank them by value\n",
    "target_sales = Recent_transactions.drop('customer_id', axis=1).groupby('article_id')['quotient'].sum()\n",
    "general_pred = target_sales.nlargest(N).index.tolist()\n",
    "general_pred = ['0' + str(article_id) for article_id in general_pred]\n",
    "general_pred_str =  ' '.join(general_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = Recent_transactions.copy()\n",
    "\n",
    "# x: number of days elapsed from the date Customer A purchased Product B to 2020-09-22\n",
    "tmp['x'] = ((last_ts - tmp['t_dat']) / np.timedelta64(1, 'D')).astype(int)\n",
    "tmp['dummy_1'] = 1 \n",
    "tmp['x'] = tmp[[\"x\", \"dummy_1\"]].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we know the function to modelize the this phenomenon we create the column y \n",
    "# y: Value to be decayed by the x \n",
    "# with the value of a, b, c and d explained before\n",
    "a, b, c, d = 2.5e4, 1.5e5, 2e-1, 1e3\n",
    "tmp['y'] = a / np.sqrt(tmp['x']) + b * np.exp(-c*tmp['x']) - d\n",
    "tmp['dummy_0'] = 0 \n",
    "tmp['y'] = tmp[[\"y\", \"dummy_0\"]].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value: y * quotient \n",
    "tmp['value'] = tmp['quotient'] * tmp['y'] \n",
    "tmp = tmp.groupby(['customer_id', 'article_id']).agg({'value': 'sum'})\n",
    "tmp = tmp.reset_index()\n",
    "\n",
    "tmp = tmp.loc[tmp['value'] > 100]\n",
    "tmp['rank'] = tmp.groupby(\"customer_id\")[\"value\"].rank(\"dense\", ascending=False)\n",
    "tmp = tmp.loc[tmp['rank'] <= 12]\n",
    "\n",
    "# We then group tmp by customer_id and rank the articles by their value\n",
    "purchase_df = tmp.sort_values(['customer_id', 'value'], ascending = False).reset_index(drop = True)\n",
    "purchase_df['prediction'] = '0' + purchase_df['article_id'].astype(str) + ' '\n",
    "purchase_df = purchase_df.groupby('customer_id').agg({'prediction': sum}).reset_index()\n",
    "purchase_df['prediction'] = purchase_df['prediction'].str.strip()\n",
    "\n",
    "# Save csv\n",
    "purchase_df.to_csv(\"data/purchase_df.csv\",index=False)\n",
    "text_file = open(\"data/general_pred_str.txt\", \"wt\")\n",
    "n = text_file.write(general_pred_str)\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28847241659200</td>\n",
       "      <td>0925246001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>116809474287335</td>\n",
       "      <td>0906305002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200292573348128</td>\n",
       "      <td>0903861001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>272412481300040</td>\n",
       "      <td>0922381001 0921906005 0923460002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>519262836338427</td>\n",
       "      <td>0804992016 0852584006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183112</th>\n",
       "      <td>18446420423308293068</td>\n",
       "      <td>0577512001 0579541001 0736923011 0786304009 08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183113</th>\n",
       "      <td>18446590778427270109</td>\n",
       "      <td>0751471022 0783346018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183114</th>\n",
       "      <td>18446630855572834764</td>\n",
       "      <td>0898713001 0886966002 0568601045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183115</th>\n",
       "      <td>18446705133201055310</td>\n",
       "      <td>0875784002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183116</th>\n",
       "      <td>18446737527580148316</td>\n",
       "      <td>0547780001 0547780040 0763988001 0763988003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183117 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 customer_id  \\\n",
       "0             28847241659200   \n",
       "1            116809474287335   \n",
       "2            200292573348128   \n",
       "3            272412481300040   \n",
       "4            519262836338427   \n",
       "...                      ...   \n",
       "183112  18446420423308293068   \n",
       "183113  18446590778427270109   \n",
       "183114  18446630855572834764   \n",
       "183115  18446705133201055310   \n",
       "183116  18446737527580148316   \n",
       "\n",
       "                                               prediction  \n",
       "0                                              0925246001  \n",
       "1                                              0906305002  \n",
       "2                                              0903861001  \n",
       "3                        0922381001 0921906005 0923460002  \n",
       "4                                   0804992016 0852584006  \n",
       "...                                                   ...  \n",
       "183112  0577512001 0579541001 0736923011 0786304009 08...  \n",
       "183113                              0751471022 0783346018  \n",
       "183114                   0898713001 0886966002 0568601045  \n",
       "183115                                         0875784002  \n",
       "183116        0547780001 0547780040 0763988001 0763988003  \n",
       "\n",
       "[183117 rows x 2 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purchase_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
