# ______________________________________________________________________________________________________
# Import des bibliothÃ¨ques
# ______________________________________________________________________________________________________

import streamlit as st
import pandas as pd
import seaborn as sns
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import plotly.express as px

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier 
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from joblib import dump, load
from datetime import datetime

from sklearn.metrics import accuracy_score, plot_confusion_matrix, roc_curve, roc_auc_score, auc, precision_score, recall_score, classification_report
from sklearn import linear_model, neighbors, svm, tree, ensemble
from sklearn.model_selection import GridSearchCV, train_test_split

# ______________________________________________________________________________________________________
# Configuration du site
# ______________________________________________________________________________________________________

st.set_page_config(page_title="JAD'Up",  layout='wide', page_icon='Agence de Marketing.ico')

st.sidebar.title("Sommaire")
st.sidebar.image('Agence de Marketing.ico')

pages = ["Introduction au jeu de donnÃ©es",
         "Analyse",
         "Preprocessing",
         "Challenge de modÃ¨les",
         "InterprÃ©tabilitÃ©",
         "Personnaliser votre campagne"]

page = st.sidebar.radio("Aller vers", pages) 


# ______________________________________________________________________________________________________
# Import du jeu de donnÃ©es et des modÃ¨les Ã  utiliser
# ______________________________________________________________________________________________________

df = pd.read_csv('bank.csv', sep = ',')
rlc = load('Regression logistique.joblib')
rfc = load('Random Forest Classifier 2.joblib')
knn = load('K plus proches voisins.joblib')
dtc = load('Decision Tree Classifier.joblib')

# ______________________________________________________________________________________________________
# PrÃ©paration des jeux de donnÃ©es Ã  utiliser
# ______________________________________________________________________________________________________

df2 = df.copy()
# Creation de tranches d'Ã¢ges
df2['t_age'] = pd.cut(x = df2['age'], bins = [17, 30, 40, 50, 65, 96], labels = ['18-30', '30-40','40-50', '50-65','65-95'])
# Creation de tranches de solde compte bancaire = balance
df2['t_balance'] = pd.qcut(x=df2["balance"], q=4, labels=[1,2,3,4])
# Creation de tranches de durÃ©e de contact = duration
df2['t_duration'] = pd.qcut(df2["duration"], q=4, labels=[1,2,3,4])
# Creation de tranches de durÃ©e de contact = duration
df2['t_duration'] = pd.qcut(df2["duration"], q=4, labels=[1,2,3,4])
# Creation de tranches de nombre de contact = campaign > Corrige le problÃ¨me de valeurs abbÃ©rantes et limite Ã  4 contacts
df2['t_campaign'] = pd.cut(x = df2['campaign'], bins = [0, 1, 2, 3, 99], labels = [1, 2, 3, 4])
# CrÃ©ation d'une catÃ©gorie pour contact campagne prÃ©cÃ©dente oui/non
df2['contact_last_campaign'] = np.where(df2['pdays']>=0, 'yes', 'no')
# CrÃ©ation de tranches en fonction du dÃ©lai Ã©coulÃ©
df2['t_pdays'] = pd.cut(x = df2['pdays'], bins = [-2, 0, 200, 999], labels = ['NON CONTACTE', 'MOINS DE 200J', 'PLUS DE 200J'])
# Creation de tranches de nombre de contact avant la campagne
df2['previous'] = pd.cut(x = df2['previous'], bins = [0, 1, 2, 3, 99], labels = [1, 2, 3, 4])
# Suppression des colonnes dummies"Ã©es"
drop_cols=['age','balance','duration','campaign','pdays','previous']
df2 = df2.drop(drop_cols, axis=1)
# CrÃ©ation de dummies
var=['marital','education','poutcome','contact','t_age','t_balance','t_duration','t_campaign','t_pdays','month']
df2= df2.join(pd.get_dummies(df2[var], prefix=var))
df2 = df2.drop(df2[var], axis=1)
# Transformation en numÃ©rique
le = LabelEncoder()
df2['job2']= le.fit_transform(df2['job'])
df2 = df2.drop(['job'], axis=1)
# Remplace yes/no par 1/0
var = ["default", "housing","loan","deposit","contact_last_campaign"]
df2[var] = df2[var].replace(('yes', 'no'), (1, 0))

# ---------- Split jeu entrainement et jeu de test -----------

# Isoler les features de la target
target = df2['deposit']
feats = df2.drop(['deposit'], axis=1)

# SÃ©paration des donnÃ©es en jeu d'entraÃ®nement et de test
X_train, X_test, y_train, y_test = train_test_split(feats, target, test_size=0.25, random_state=123)

# Normaliser les donnÃ©es - MinMaxScaler
scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# ---------- Jeu de donnÃ©es modifiÃ© -----------

feats_modif=feats.copy()
for month in ['month_jan', 'month_feb','month_mar', 'month_apr', 'month_may','month_jun', 'month_jul','month_aug', 'month_sep','month_oct', 'month_nov','month_dec']:
  feats_modif[month]=0
for duration in ["t_duration_1", "t_duration_2", "t_duration_3", "t_duration_4"]:
  feats_modif[duration]=0

# ---------- Fonction de description -----------

def describe_df(df):
    """
    Fonction amÃ©liorÃ©e de description des colonnes, elle permet d'identifier :
    le type de la colonne , le nb de valeur vide (nan), le nb de valeurs uniques, le pourcentage de rÃ©partition des valeurs
    INPUT : le dataframe
    OUTPUT : tableau d'analyse
    """
    res = pd.DataFrame(index=["Name","Type", "Nan", "Unique","Min","Max","Values","Pourcentage"])
    for col in df.columns:
        df_col = df[col]
        res[col] = [
            df_col.name,
            df_col.dtype,
            df_col.isnull().sum(),
            len(df_col.unique()),
            df_col.min(),
            df_col.max(),
            df_col.unique(),
            (df_col.value_counts(ascending=False, normalize=True) * 100)
                .apply(int)
                .to_json(),
        ]
    return res.T


# ______________________________________________________________________________________________________
# 1/ Introduction au jeu de donnÃ©es
# ______________________________________________________________________________________________________

if page==pages[0]: 

  st.title("Description du jeu de donnÃ©es")

  st.markdown("""
           Ce jeu de donnÃ©es est composÃ© de donnÃ©es personnelles sur des clients dâ€™une banque qui ont Ã©tÃ© â€œtÃ©lÃ©marketÃ©sâ€ pour souscrire Ã  un produit
           que lâ€™on appelle un 'dÃ©pÃ´t Ã  terme'. \n
           Lorsquâ€™un client souscrit Ã  ce produit, il place une quantitÃ© dâ€™argent dans un compte spÃ©cifique et ne pourra pas toucher ces fonds avant lâ€™expiration
           du terme. \n
           En Ã©change, le client reÃ§oit des intÃ©rÃªts de la part de la banque Ã  la fin du terme. 
           Le jeu de donnÃ©es est tÃ©lÃ©chargeable au lien suivant :
           https://www.kaggle.com/janiobachmann/bank-marketing-dataset
           """)
         
# ---------- Les chiffres clÃ©s -----------

  st.header("Les chiffres clÃ©s :")
  col1, col2, col3, col4, col5 = st.columns(5)
  col1.write('')
  col2.metric("Nombre de clients", "11 162")
  col3.metric("Nombre de features", "17")
  col4.metric("Proportion des cibles", "47%")
  col5.write('')
         
# ---------- les variables  -----------

  st.header("Description des variables :")         
  st.image("Describe.png")

  #var = pd.DataFrame({"Nom des variables": ["age","job","marital","education","default","balance","housing","loan","contact","day","month","duration","campaign","pdays","previous","poutcome","deposit"],
  #  "Description": ["Age du client","Profession","Statut marital","Niveau d'Ã©tudes","DÃ©faut de paiement","Solde du compte","PrÃªt immo","PrÃªt perso",
  #  "Type de contact","Dernier jour de contact","Dernier mois de  contact","DurÃ©e du contact (secondes)","Nombre de contacts","Nb jours Ã©coulÃ©s depuis le dernier contact","Nb de contacts",
  #  "RÃ©sultat de la campagne prÃ©cÃ©dente","RÃ©sultat de la campagne en cours"]
  #  })

  #st.write(var)

# ---------- AperÃ§u -----------

  describe = st.checkbox("AperÃ§u du jeu de donnÃ©es")
  if describe:
    st.write(df)

# ---------- Ce qu'il faut comprendre -----------

  st.header("Ce qu'il faut retenir :")
  st.markdown("""
           On remarque que certaines variables sont la rÃ©sultante de la campagne en cours : 
           * contact
           * day
           * month
           * duration
           * campaign
           La variable **deposit** est notre variable cible.
           """)
         
# ______________________________________________________________________________________________________
# 2/ Analyse du jeu de donnÃ©es
# ______________________________________________________________________________________________________

if page==pages[1]: 

  st.title("Analyse du jeu de donnÃ©es")
  st.markdown("""
           Lâ€™analyse descriptive est le terme donnÃ© Ã  lâ€™analyse des donnÃ©es permettant de dÃ©crire et de rÃ©sumer des donnÃ©es historiques de maniÃ¨re significative
           afin que des **insights** en ressortent. \n
           Lâ€™analyse descriptive de notre jeu de donnÃ©es va nous fournir les informations de base sur les variables, leur rÃ©partition, et leurs relations potentielles. \n
           Nous allons pouvoir observer - _Ã  premiÃ¨re vue_ - les Ã©lÃ©ments qui ont favorisÃ©, ou Ã  l'inverse dÃ©favorisÃ©, la performance de la campagne commerciale.
           """)

  st.write(" ")

# ---------- Les distributions par type de variables -----------

  st.subheader("Les distributions par type de variables")
         
  col1, col2 = st.columns(2)
  col1.subheader("Variables numÃ©riques")
  col2.subheader("Variables catÃ©gorielles")
  df2 = df.copy()
  numerics = df2.select_dtypes(include=['int16', 'int32', 'int64', 'float16', 'float32', 'float64']).columns
  categoricals= df2.select_dtypes(include=['object','category']).columns

# variables numÃ©riques

  tab1, tab2 = col1.tabs(["ðŸ“ˆ Chart", "ðŸ“‹ Describe"])
         
  option = tab1.selectbox("Choix une variable numÃ©rique :",numerics)
  hist = px.histogram(df2,x=option,color="deposit",barmode="group")
  tab1.plotly_chart(hist)
         
  describe= df2[numerics].describe().transpose()
  tab2.write(describe)

  if option=="age":
    col1.info("Les Ã¢ges extrÃªmes semblent avoir une plus forte adhÃ©rence avec la campagne.")
  elif option=="duration":
    col1.info("On remarque que plus la durÃ©e de contact augmente et plus les clients semblent souscrire Ã  la campagne.")

# variables catÃ©gorielles

  tab3, tab4 = col2.tabs(["ðŸ“ˆ Chart", "ðŸ“‹ Describe"])

  option = tab3.selectbox("Choix une variable catÃ©gorielle :", categoricals)
  hist = px.histogram(df2,y=option,color="deposit",barmode="group")
  tab3.plotly_chart(hist)
         
  describe= df2[categoricals].describe().transpose()
  tab4.write(describe)

  if option=="marital":
    col2.info("Le statut marital 'single' semble rendre plus favorable la campagne.")
  elif option=="housing":
    col2.info("L'absence de prÃªt immo semble augmenter les chances de rÃ©pondre favorablement Ã  la campagne.")
  elif option=="month":
    col2.info("On observe que certains mois comme Mars, Septembre et Octobre semblent plus propices  la performance de la campagne."
              "\n A l'inverse les mois de Mai Ã  Aout semblent diminuer les chances de concrÃ©tisation. ")
  elif option=="poutcome":
    col2.info("Les clients ayant rÃ©pondu positivement Ã  la campagne prÃ©cÃ©dente sont les plus susceptibles de renouveller un dÃ©pÃ´t.")

# ---------- Les correlations -----------

  st.header("Analyse des corrÃ©lations")
  tab1, tab2 = st.tabs(["â–© Matrice", "ðŸ“ˆ Chart"])
         
# Matrice de correlation

  col1, col2 = tab1.columns((2, 1))

  le = LabelEncoder()
  df2=df.copy()
  for col in df2.columns:
    df2[col]= le.fit_transform(df2[col])
  
  fig = plt.figure(figsize=(15,10))
  sns.heatmap(df2.corr(), annot=True, cmap='RdBu_r', center=0)
  col1.pyplot(fig)
  col2.write('')

# CorrÃ©lations directes

  col3, col4 = tab2.columns((3, 1))

  corr=pd.DataFrame(df2.corr()["deposit"])
  corr=corr.sort_values("deposit",ascending=False, key=abs)
         
  fig = plt.figure(figsize=(10,5))
  df2.corr()['deposit'].sort_values().drop('deposit').plot(kind='bar', cmap='viridis')
  col3.pyplot(fig)

# CorrÃ©lations coefficients

  coef=df2.corr()["deposit"]
  col4.write(coef)


# ---------- Les observations -----------

  st.header("Observations")
  st.info("""
           On remarque que 8 324 clients n'ont pas Ã©tÃ© contactÃ©s lors de la campagne prÃ©cÃ©dente.
           Lorsque PREVIOUS = 0 alors PDAYS = -1
           """)
  st.info("""
           Dans l'ordre, les variables les plus corrÃ©lÃ©es (valeur absolue) avec la target _[deposit]_ sont :
           * **_duration_** = DurÃ©e du contact (en secondes)
           * **_contact_** = Type de contact 
           * housing = PrÃªt immo
           * previous = Nb contacts au cours de la campagne prÃ©cÃ©dente
           * housing = pdays = Nb jours Ã©coulÃ©s depuis le dernier contact de la campagne prÃ©cÃ©dente
           * previous = balance = Solde compte bancaire
           **Attention** , les **_deux variables_** correspondent Ã  des donnÃ©es non connues Ã  priori (avant lancement de la campagne)
           """)
         
# ______________________________________________________________________________________________________
# 3/ PrÃ©processing
# ______________________________________________________________________________________________________

if page==pages[2]: 

  st.title("PrÃ©processing - ModÃ¨les prÃ©dictifs")


# ---------- Le prÃ©processing, Ã§a sert Ã  quoi -----------

  expander1 = st.expander("Le prÃ©processing, Ã§a sert Ã  quoi ?")

  expander1.markdown("""
           Le prÃ©processing est une de composante essentielle de la data science.
           Cette Ã©tape dÃ©crit toutes les **transformations** effectuÃ©es sur le jeu de donnÃ©es initial et indispensables Ã  la crÃ©ation du modÃ¨le d'apprentissage fiable et robuste.
           Les algorithmes d'apprentissage automatique fonctionnent mieux lorsque les donnÃ©es sont prÃ©sentÃ©es dans un format qui met en Ã©vidence les aspects pertinents requis pour rÃ©soudre un problÃ¨me.
           Les fonctions de prÃ©processing consistent Ã  **restructurer** les donnÃ©es brutes sous une forme adaptÃ©e Ã  des types particuliers d'algorithmes. Les Ã©tapes sont :
           * la transformation des donnÃ©es,
           * la rÃ©duction des donnÃ©es,
           * la sÃ©lection des variables
           * et Ã  la mise Ã  l'Ã©chelle.
           """)
  
  expander1.image('preprocessing.JPG', caption='Les Ã©tapes de prÃ©processing')     


# ---------- Les Ã©tapes de prÃ©processing -----------

  st.header("Les Ã©tapes de prÃ©processing appliquÃ©es :")

# Variables numÃ©riques

  st.subheader("Le traitement des variables numÃ©riques")
  code = ''' 
    # Creation de tranches d'Ã¢ges
    df2['t_age'] = pd.cut(x = df2['age'], bins = [17, 30, 40, 50, 65, 96], labels = ['18-30', '30-40','40-50', '50-65','65-95'])

    # Creation de tranches de solde compte bancaire = balance
    df2['t_balance'] = pd.qcut(x=df2["balance"], q=4, labels=[1,2,3,4])

    # Creation de tranches de durÃ©e de contact = duration
    df2['t_duration'] = pd.qcut(df2["duration"], q=4, labels=[1,2,3,4])

    # Creation de tranches de durÃ©e de contact = duration
    df2['t_duration'] = pd.qcut(df2["duration"], q=4, labels=[1,2,3,4])

    # Creation de tranches de nombre de contact = campaign > Corrige le problÃ¨me de valeurs abbÃ©rantes et limite Ã  4 contacts
    df2['t_campaign'] = pd.cut(x = df2['campaign'], bins = [0, 1, 2, 3, 99], labels = [1, 2, 3, 4])

    # CrÃ©ation d'une catÃ©gorie pour contact campagne prÃ©cÃ©dente oui/non
    df2['contact_last_campaign'] = np.where(df2['pdays']>=0, 'yes', 'no')

    # CrÃ©ation de tranches en fonction du dÃ©lai Ã©coulÃ©
    df2['t_pdays'] = pd.cut(x = df2['pdays'], bins = [-2, 0, 200, 999], labels = ['NON CONTACTE', 'MOINS DE 200J', 'PLUS DE 200J'])

    # Creation de tranches de nombre de contact avant la campagne
    df2['previous'] = pd.cut(x = df2['previous'], bins = [0, 1, 2, 3, 99], labels = [1, 2, 3, 4])

    # Suppression des colonnes dummies"Ã©es"
    drop_cols=['age','balance','duration','campaign','pdays','previous']
    df2 = df2.drop(drop_cols, axis=1)
    '''
  st.code(code, language='python')

# Variables catÃ©gorielles

  st.subheader("Le traitement des variables catÃ©gorielles")
  code = ''' 
    # CrÃ©ation de dummies
    var=['marital','education','poutcome','contact','t_age','t_balance','t_duration','t_campaign','t_pdays','month']
    df2= df2.join(pd.get_dummies(df2[var], prefix=var))
    df2 = df2.drop(df2[var], axis=1)

    # Transformation en numÃ©rique
    le = LabelEncoder()
    df2['job2']= le.fit_transform(df2['job'])
    df2 = df2.drop(['job'], axis=1)

    # Remplace yes/no par 1/0
    var = ["default", "housing","loan","deposit","contact_last_campaign"]
    df2[var] = df2[var].replace(('yes', 'no'), (1, 0))
    '''
  st.code(code, language='python')

         
# ---------- Jeu de donnÃ©es final -----------

  st.header("Le jeu de donnÃ©es final :")
  st.write(df2)
         
# ---------- Arbre de correlations aprÃ¨s preprocessing -----------

  st.header("Arbre de correlations aprÃ¨s preprocessing :")

  fig = plt.figure(figsize=(20,8))
  df2.corr()['deposit'].sort_values().drop('deposit').plot(kind='bar', cmap='viridis')
  st.pyplot(fig)

# ---------- Les enseignements -----------

  st.header("Les observations :")
  st.info("""
           On voit clairement que la feature **[duration]** impacte positivement la campagne dÃ¨s lors que la valeur est Ã©levÃ©e (temps de contact). \n
           Egalement, les clients ayant rÃ©pondu favorablement Ã  la campagne prÃ©cÃ©dente **[poutcome]** semblent Ãªtre les plus susceptibles de renouveler leur action. \n
           Les mois de mars et octobre [month] semblent Ãªtre les meilleurs mois pour optimiser les leads.
           """)


# ______________________________________________________________________________________________________
# 4/ Challenge de modÃ¨les
# ______________________________________________________________________________________________________

if page==pages[3]:
         
  st.title("ModÃ¨les prÃ©dictifs")
  st.markdown("""
              Les quatre modÃ¨les prÃ©dictifs suivants ont Ã©tÃ© choisis en raison de leur Ã©quilibre entre bonne performance et durÃ©e d'exÃ©cution sur ce jeu de donnÃ©es.
              * La **rÃ©gression logistique** ou RLC
              * Le modÃ¨le **K-plus proches voisins** ou KNN
              * L'**arbre de dÃ©cision** ou DTC
              * Les **forÃªts alÃ©atoires** ou RFC 
              """)
  st.write("  ")

# ---------- Les 3 modÃ¨les -----------

  col1, col2, col3, col4 = st.columns(4)
         
  # Sauvegarde des rÃ©sulats de chacun des modÃ¨les
  models=[]
  scores =[]
  precision=[]
  rappel=[]
  roc=[]
         
# RÃ©gression logistique -----------------------------------------------------------------------

  with col1:
    st.subheader("ModÃ¨le RLC")
    st.image("regression-lineaire.png")
         
    #rlc = linear_model.LogisticRegression(C=10)
    #rlc.fit(X_train, y_train)
        
    st.metric("Score train", "{:.2%}".format(rlc.score(X_train, y_train)))
    st.metric("Score test", "{:.2%}".format(rlc.score(X_test, y_test)))
    st.metric("Precision Score", "{:.2%}".format(precision_score(y_test, rlc.predict(X_test))))

    y_pred = rlc.predict(X_test)
    st.write("Matrice de confusion :")
    st.write(pd.crosstab(y_test, y_pred, rownames=['Classe rÃ©elle'], colnames=['Classe prÃ©dite']))

    # Sauvegarde des rÃ©sultats
    models.append("Regression logistique")
    scores.append(rlc.score(X_test, y_test))
    precision.append(precision_score(y_test, rlc.predict(X_test)))
    rappel.append(recall_score(y_test, rlc.predict(X_test)))
    roc.append(roc_auc_score(y_test, rlc.predict(X_test)))
    probs_rlc = rlc.predict_proba(X_test)
         
# K plus proche voisins -----------------------------------------------------------------------

  with col2:
    st.subheader("ModÃ¨le KNN")
    st.image("networking.png")

    #knn = neighbors.KNeighborsClassifier(n_neighbors=39)
    #knn.fit(X_train, y_train)
      
    st.metric("Score train", "{:.2%}".format(knn.score(X_train, y_train)))
    st.metric("Score test", "{:.2%}".format(knn.score(X_test, y_test)))
    st.metric("Precision Score", "{:.2%}".format(precision_score(y_test, knn.predict(X_test))))

    y_pred = knn.predict(X_test)
    st.write("Matrice de confusion :")
    st.write(pd.crosstab(y_test, y_pred, rownames=['Classe rÃ©elle'], colnames=['Classe prÃ©dite']))

    # Sauvegarde des rÃ©sultats
    models.append("K plus proches voisins")
    scores.append(knn.score(X_test, y_test))
    precision.append(precision_score(y_test, knn.predict(X_test)))
    rappel.append(recall_score(y_test, knn.predict(X_test)))
    roc.append(roc_auc_score(y_test, knn.predict(X_test)))
    probs_knn = knn.predict_proba(X_test)
     
# Arbre de dÃ©cision -----------------------------------------------------------------------

  with col3:
    st.subheader("ModÃ¨le DTC")
    st.image("arbre-de-decision.png")

    #dtc = tree.DecisionTreeClassifier(max_depth=9)
    #dtc.fit(X_train, y_train)  
        
    st.metric("Score train", "{:.2%}".format(dtc.score(X_train, y_train)))
    st.metric("Score test", "{:.2%}".format(dtc.score(X_test, y_test)))
    st.metric("Precision Score", "{:.2%}".format(precision_score(y_test, dtc.predict(X_test))))

    y_pred = dtc.predict(X_test)
    st.write("Matrice de confusion :")
    st.write(pd.crosstab(y_test, y_pred, rownames=['Classe rÃ©elle'], colnames=['Classe prÃ©dite']))

    # Sauvegarde des rÃ©sultats
    models.append("Decision Tree")
    scores.append(dtc.score(X_test, y_test))
    precision.append(precision_score(y_test, dtc.predict(X_test)))
    rappel.append(recall_score(y_test, dtc.predict(X_test)))
    roc.append(roc_auc_score(y_test, dtc.predict(X_test)))
    probs_dtc = dtc.predict_proba(X_test)

# Random Forest -----------------------------------------------------------------------

  with col4:
    st.subheader("ModÃ¨le RFC")
    st.image("foret.png")

    #rfc = ensemble.RandomForestClassifier(n_jobs=1) 
    #rfc.fit(X_train, y_train)
    
    st.metric("Score train", "{:.2%}".format(rfc.score(X_train, y_train)))
    st.metric("Score test", "{:.2%}".format(rfc.score(X_test, y_test)))
    st.metric("Precision Score", "{:.2%}".format(precision_score(y_test, rfc.predict(X_test))))

    y_pred = rfc.predict(X_test)
    st.write("Matrice de confusion :")
    st.write(pd.crosstab(y_test, y_pred, rownames=['Classe rÃ©elle'], colnames=['Classe prÃ©dite']))

    # Sauvegarde des rÃ©sultats
    models.append("Random Forest")
    scores.append(rfc.score(X_test, y_test))
    precision.append(precision_score(y_test, rfc.predict(X_test)))
    rappel.append(recall_score(y_test, rfc.predict(X_test)))
    roc.append(roc_auc_score(y_test, rfc.predict(X_test)))
    probs_rfc = rfc.predict_proba(X_test)

# Comparaison des rÃ©sultats -----------------------------------------------------------------------

  st.write(" ")
  
  tab1, tab2 = st.columns(2)

  # Recap des scores
  compare = pd.DataFrame(models)
  compare.columns = ['model']
  compare["accuracy"]=scores
  compare["precision"]=precision
  compare["rappel"]=rappel
  compare["roc"]=roc

  #Graphique de comparaison des rÃ©sultats
  tab1.subheader("ðŸ“Š Graphique de comparaison")
  fig = plt.figure(figsize=(20,6))
  bar = px.bar(compare, x="model", y=['accuracy', 'precision', 'rappel','roc'], barmode='group')
  bar.add_hline(y=0.80, line_width=3, line_dash="dash", line_color="black")
  tab1.plotly_chart(bar)     

  # Comparaison avec l'indice des ROC
  tab2.subheader("ðŸ“ˆ Courbe ROC")

  # Regression logistique
  fpr_rlc, tpr_rlc, seuils = roc_curve(y_test, probs_rlc[:,1])
  roc_auc_rlc = auc(fpr_rlc, tpr_rlc)

  # K plus proches voisins
  fpr_knn, tpr_knn, seuils = roc_curve(y_test, probs_knn[:,1])
  roc_auc_knn = auc(fpr_knn, tpr_knn)

  # Decision Tree
  fpr_dtc, tpr_dtc, seuils = roc_curve(y_test, probs_dtc[:,1])
  roc_auc_dtc = auc(fpr_dtc, tpr_dtc)

  # Random Forest
  fpr_rfc, tpr_rfc, seuils = roc_curve(y_test, probs_rfc[:,1])
  roc_auc_rfc = auc(fpr_rfc, tpr_rfc)

  # Les courbes
  import plotly.graph_objects as go         
  fig = go.Figure(data=go.Scatter(x=fpr_rlc, y=tpr_rlc , mode='lines', name='ModÃ¨le RLC (auc = %0.2f)' % roc_auc_rlc))
  fig.add_trace(go.Scatter(x=fpr_knn, y=tpr_knn , mode='lines', name='ModÃ¨le KNN (auc = %0.2f)' % roc_auc_knn))
  fig.add_trace(go.Scatter(x=fpr_dtc, y=tpr_dtc , mode='lines', name='ModÃ¨le DTC (auc = %0.2f)' % roc_auc_dtc))
  fig.add_trace(go.Scatter(x=fpr_rfc, y=tpr_rfc , mode='lines', name='ModÃ¨le RFC (auc = %0.2f)' % roc_auc_rfc))
  fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], name='AlÃ©atoire (auc = 0.5)', line = dict(color='black', width=2, dash='dot')))
  fig.update_layout(height=450, width=700, legend=dict(yanchor="top", y=0.5, xanchor="left", x=0.65))
  tab2.plotly_chart(fig)          
         
  with tab2.expander("Plus d'explication sur ce graphique :"):
    st.write("""
         La courbe ROC (pour **Receiver Operating Characteristic**) est une courbe qui reprÃ©sente le comportement de notre classifieur Ã  deux classes pour tous les seuils de dÃ©tection possibles.
         \n Si nous utilisons les probabilitÃ©s dâ€™appartenance Ã  la classe cible renvoyÃ©es par notre classifieur au lieu des prÃ©dictions,
         nous pourrions choisir librement Ã  partir de quelle probabilitÃ© nous considÃ©rons quâ€™un item est de cette classe.
         \n En prenant des seuils de 0 Ã  1 (ou 100%), nous balayons **toutes les possibilitÃ©s**.
         \n A chaque seuil, nous pouvons calculer le taux de vrais positifs et le taux de faux positifs.
         \n La courbe ROC reprÃ©sente ces rÃ©sultats avec le taux de faux positifs sur lâ€™axe x et le taux de vrais positifs sur lâ€™axe y.
     """)

  st.subheader("ðŸ† Le modÃ¨le gagnant")
  st.success("Le modÃ¨le **Random Forest** obtient les meilleures performances et semble le plus Ã©quilibrÃ©. Il permet de maximiser les positifs.")

         
         
# ______________________________________________________________________________________________________
# 5/ BONUS
# ______________________________________________________________________________________________________

if page==pages[5]: 

  st.title("âš™ï¸ Personnaliser votre campagne")
  st.write(" ")
  st.write(" ")

  col1, col2, col3, col4, col5  = st.columns((1, 2 , 1, 2, 1))

# Volet personnalisation de la campagne -----------------------------------------------------------------------

  model = col2.radio(
     "âœ¨Quel modÃ¨le prÃ©dictif souhaitez-vous privilÃ©gier ?",
     ('RÃ©gression logistique', 'K-Plus proches voisins', 'Arbre de dÃ©cisions', 'FÃ´rets alÃ©atoires'), index=3)
  
  seuil = col2.number_input(
      "ðŸŽšï¸ Quel seuil pour les prÃ©dictions ?", min_value=0.1, max_value=0.9, value=0.5)         
         
  m = col4.select_slider(
     'ðŸ“… Quel est le mois prÃ©visionnel de lancement de cette nouvelle campagne ?',
     options=['Janvier', 'FÃ©vrier','Mars', 'Avril', 'Mai','Juin', 'Juillet', 'AoÃ»t', 'Septembre','Octobre', 'Novembre','DÃ©cembre'])
         
  d = col4.select_slider(
     "âŒš A combien de minutes estimez-vous la durÃ©e d'un appel tÃ©lÃ©phonique pour cette campagne ?",
     options=["1:00", "2:00", "3:00", "4:00", "5:00", "6:00", "7:00", "8:00", "9:00", "10:00"], value="5:00")
   
  st.write(" ")

# Volet entrainement du modÃ¨le de la campagne -----------------------------------------------------------------------

  col4, col5, col6  = st.columns(3)

  if col5.button('Lancer la prÃ©diction'): 
    feats_modif_x=feats_modif.copy()

    # Choix du modÃ¨le -----------------------------------
    if model == "RÃ©gression logistique":
      classifieur = rlc
    elif model == "K-Plus proches voisins":
      classifieur = knn
    elif model == "Arbre de dÃ©cisions":
      classifieur = dtc
    else:
      classifieur = rfc

    # Choix du mois -----------------------------------
    if m == "Janvier":
      feats_modif_x["month_jan"]=1
    elif m == "FÃ©vrier":
      feats_modif_x["month_feb"]=1
    elif m == "Mars":
      feats_modif_x["month_mar"]=1
    elif m == "Avril":
      feats_modif_x["month_apr"]=1
    elif m == "Mai":
      feats_modif_x["month_may"]=1
    elif m == "Juin":
      feats_modif_x["month_jun"]=1
    elif m == "Juillet":
      feats_modif_x["month_jul"]=1
    elif m == "AoÃ»t":
      feats_modif_x["month_aug"]=1
    elif m == "Septembre":
      feats_modif_x["month_sep"]=1
    elif m == "Octobre":
      feats_modif_x["month_oct"]=1
    elif m == "Novembre":
      feats_modif_x["month_nov"]=1
    else:
      feats_modif_x["month_dec"]=1

    # Choix de la durÃ©e -----------------------------------
    if d in ["1:00","2:00"]:
      feats_modif_x["t_duration_1"]=1
    elif d in ["3:00","4:00"]:
      feats_modif_x["t_duration_2"]=1    
    elif d in ["4:00","5:00","6:00","7:00"]:
      feats_modif_x["t_duration_3"]=1                  
    else:
      feats_modif_x["t_duration_4"]=1    

    # Entrainement du modÃ¨le choisi -----------------------------------
         
    col5.write(classifieur)
    col5.write(" ")  
         
    y_pred = classifieur.predict(feats_modif_x)
    probas=classifieur.predict_proba(feats_modif_x)
    probas=pd.DataFrame(probas, columns=['NO','ProbabilitÃ©s'], index=feats_modif_x.index)
    probas = probas.drop(['NO'], axis=1)
    probas['Classification'] = np.where(probas['ProbabilitÃ©s']>seuil,1,0)         

    col4.write(" ")
    col4.write(" ") 
    col4.write(" ") 
    col4.subheader("Distribution des probabilitÃ©s")
    fig = px.histogram(probas,x="ProbabilitÃ©s",color="Classification", nbins=100)
    fig.add_vline(x=seuil, line_width=3, line_dash="dash", line_color="black")
    fig.update_layout(height=400, width=500, legend=dict(yanchor="top", y=0.8, xanchor="left", x=0.8))
    col4.plotly_chart(fig) 
         
    col5.write(" ")
    col5.write(" ") 
    col5.write(" ") 
    col5.subheader("RÃ©partition des prÃ©dictions")
    pie = px.pie(probas, values='ProbabilitÃ©s', names='Classification', hole=.3)
    pie.update_layout(height=300, width=300, legend=dict(yanchor="top", y=0.8, xanchor="left", x=0.8))
    col5.plotly_chart(pie)
         
    col6.metric("Temperature", "70 Â°F", "1.2 Â°F")
    col6.metric("Wind", "9 mph", "-8%")
    col6.metric("Humidity", "86%", "4%")
