# ______________________________________________________________________________________________________
# Import des biblioth√®ques
# ______________________________________________________________________________________________________

import streamlit as st
import pandas as pd
import seaborn as sns
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import plotly.express as px

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier 
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from joblib import dump, load
from datetime import datetime

from sklearn.metrics import accuracy_score, plot_confusion_matrix, roc_curve, roc_auc_score, auc, precision_score, recall_score, classification_report
from sklearn import linear_model, neighbors, svm, tree, ensemble
from sklearn.model_selection import GridSearchCV, train_test_split

# ______________________________________________________________________________________________________
# Configuration du site
# ______________________________________________________________________________________________________

st.set_page_config(page_title="JAD'Up",  layout='wide', page_icon='Agence de Marketing.ico')

st.sidebar.title("Sommaire")
st.sidebar.image('Agence de Marketing.ico')

pages = ["Introduction au jeu de donn√©es",
         "Analyse",
         "Preprocessing",
         "Challenge de mod√®les",
         "Interpr√©tabilit√©",
         "Personnaliser votre campagne"]

page = st.sidebar.radio("Aller vers", pages) 


# ______________________________________________________________________________________________________
# Import du jeu de donn√©es et des mod√®les √† utiliser
# ______________________________________________________________________________________________________

df = pd.read_csv('bank.csv', sep = ',')
rlc = load('Regression logistique.joblib')
rfc = load('Random Forest Classifier.joblib')
knn = load('K plus proches voisins.joblib')
dtc = load('Decision Tree Classifier.joblib')
compare = pd.read_csv('compare_scores.csv', sep = ',')

# ______________________________________________________________________________________________________
# Pr√©paration des jeux de donn√©es √† utiliser
# ______________________________________________________________________________________________________

df2 = df.copy()
# Creation de tranches d'√¢ges
df2['t_age'] = pd.cut(x = df2['age'], bins = [17, 30, 40, 50, 65, 96], labels = ['18-30', '30-40','40-50', '50-65','65-95'])
# Creation de tranches de solde compte bancaire = balance
df2['t_balance'] = pd.qcut(x=df2["balance"], q=4, labels=[1,2,3,4])
# Creation de tranches de dur√©e de contact = duration
df2['t_duration'] = pd.qcut(df2["duration"], q=4, labels=[1,2,3,4])
# Creation de tranches de dur√©e de contact = duration
df2['t_duration'] = pd.qcut(df2["duration"], q=4, labels=[1,2,3,4])
# Creation de tranches de nombre de contact = campaign > Corrige le probl√®me de valeurs abb√©rantes et limite √† 4 contacts
df2['t_campaign'] = pd.cut(x = df2['campaign'], bins = [0, 1, 2, 3, 99], labels = [1, 2, 3, 4])
# Cr√©ation d'une cat√©gorie pour contact campagne pr√©c√©dente oui/non
df2['contact_last_campaign'] = np.where(df2['pdays']>=0, 'yes', 'no')
# Cr√©ation de tranches en fonction du d√©lai √©coul√©
df2['t_pdays'] = pd.cut(x = df2['pdays'], bins = [-2, 0, 200, 999], labels = ['NON CONTACTE', 'MOINS DE 200J', 'PLUS DE 200J'])
# Creation de tranches de nombre de contact avant la campagne
df2['previous'] = pd.cut(x = df2['previous'], bins = [0, 1, 2, 3, 99], labels = [1, 2, 3, 4])
# Suppression des colonnes dummies"√©es"
drop_cols=['age','balance','duration','campaign','pdays','previous']
df2 = df2.drop(drop_cols, axis=1)
# Cr√©ation de dummies
var=['marital','education','poutcome','contact','t_age','t_balance','t_duration','t_campaign','t_pdays','month']
df2= df2.join(pd.get_dummies(df2[var], prefix=var))
df2 = df2.drop(df2[var], axis=1)
# Transformation en num√©rique
le = LabelEncoder()
df2['job2']= le.fit_transform(df2['job'])
df2 = df2.drop(['job'], axis=1)
# Remplace yes/no par 1/0
var = ["default", "housing","loan","deposit","contact_last_campaign"]
df2[var] = df2[var].replace(('yes', 'no'), (1, 0))

# ---------- Split jeu entrainement et jeu de test -----------

# Isoler les features de la target
target = df2['deposit']
feats = df2.drop(['deposit'], axis=1)

# S√©paration des donn√©es en jeu d'entra√Ænement et de test
X_train, X_test, y_train, y_test = train_test_split(feats, target, test_size=0.25, random_state=123)

# Normaliser les donn√©es - MinMaxScaler
scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# ---------- Jeu de donn√©es modifi√© -----------

feats_modif=feats.copy()
for month in ['month_jan', 'month_feb','month_mar', 'month_apr', 'month_may','month_jun', 'month_jul','month_aug', 'month_sep','month_oct', 'month_nov','month_dec']:
  feats_modif[month]=0
for duration in ["t_duration_1", "t_duration_2", "t_duration_3", "t_duration_4"]:
  feats_modif[duration]=0

# ---------- Fonction de description -----------

def describe_df(df):
    """
    Fonction am√©lior√©e de description des colonnes, elle permet d'identifier :
    le type de la colonne , le nb de valeur vide (nan), le nb de valeurs uniques, le pourcentage de r√©partition des valeurs
    INPUT : le dataframe
    OUTPUT : tableau d'analyse
    """
    res = pd.DataFrame(index=["Name","Type", "Nan", "Unique","Min","Max","Values","Pourcentage"])
    for col in df.columns:
        df_col = df[col]
        res[col] = [
            df_col.name,
            df_col.dtype,
            df_col.isnull().sum(),
            len(df_col.unique()),
            df_col.min(),
            df_col.max(),
            df_col.unique(),
            (df_col.value_counts(ascending=False, normalize=True) * 100)
                .apply(int)
                .to_json(),
        ]
    return res.T


# ______________________________________________________________________________________________________
# 1/ Introduction au jeu de donn√©es
# ______________________________________________________________________________________________________

if page==pages[0]: 

  st.title("Description du jeu de donn√©es")

  st.markdown("""
           Ce jeu de donn√©es est compos√© de donn√©es personnelles sur des clients d‚Äôune banque qui ont √©t√© ‚Äút√©l√©market√©s‚Äù pour souscrire √† un produit
           que l‚Äôon appelle un 'd√©p√¥t √† terme'. \n
           Lorsqu‚Äôun client souscrit √† ce produit, il place une quantit√© d‚Äôargent dans un compte sp√©cifique et ne pourra pas toucher ces fonds avant l‚Äôexpiration
           du terme. \n
           En √©change, le client re√ßoit des int√©r√™ts de la part de la banque √† la fin du terme. 
           Le jeu de donn√©es est t√©l√©chargeable au lien suivant :
           https://www.kaggle.com/janiobachmann/bank-marketing-dataset
           """)
         
# ---------- Les chiffres cl√©s -----------

  st.header("Les chiffres cl√©s :")
  col1, col2, col3, col4, col5 = st.columns(5)
  col1.write('')
  col2.metric("Nombre de clients", "11 162")
  col3.metric("Nombre de features", "17")
  col4.metric("Proportion des cibles", "47%")
  col5.write('')
         
# ---------- les variables  -----------

  st.header("Description des variables :")         
  st.image("Describe.png")

  #var = pd.DataFrame({"Nom des variables": ["age","job","marital","education","default","balance","housing","loan","contact","day","month","duration","campaign","pdays","previous","poutcome","deposit"],
  #  "Description": ["Age du client","Profession","Statut marital","Niveau d'√©tudes","D√©faut de paiement","Solde du compte","Pr√™t immo","Pr√™t perso",
  #  "Type de contact","Dernier jour de contact","Dernier mois de  contact","Dur√©e du contact (secondes)","Nombre de contacts","Nb jours √©coul√©s depuis le dernier contact","Nb de contacts",
  #  "R√©sultat de la campagne pr√©c√©dente","R√©sultat de la campagne en cours"]
  #  })

  #st.write(var)

# ---------- Aper√ßu -----------

  describe = st.checkbox("Aper√ßu du jeu de donn√©es")
  if describe:
    st.write(df)

# ---------- Ce qu'il faut comprendre -----------

  st.header("Ce qu'il faut retenir :")
  st.markdown("""
           On remarque que certaines variables sont la r√©sultante de la campagne en cours : 
           * contact
           * day
           * month
           * duration
           * campaign
           La variable **deposit** est notre variable cible.
           """)
         
# ______________________________________________________________________________________________________
# 2/ Analyse du jeu de donn√©es
# ______________________________________________________________________________________________________

if page==pages[1]: 

  st.title("Analyse du jeu de donn√©es")
  st.markdown("""
           L‚Äôanalyse descriptive est le terme donn√© √† l‚Äôanalyse des donn√©es permettant de d√©crire et de r√©sumer des donn√©es historiques de mani√®re significative
           afin que des **insights** en ressortent. \n
           L‚Äôanalyse descriptive de notre jeu de donn√©es va nous fournir les informations de base sur les variables, leur r√©partition, et leurs relations potentielles. \n
           Nous allons pouvoir observer - _√† premi√®re vue_ - les √©l√©ments qui ont favoris√©, ou √† l'inverse d√©favoris√©, la performance de la campagne commerciale.
           """)

  st.write(" ")

# ---------- Les distributions par type de variables -----------

  st.subheader("Les distributions par type de variables")
         
  col1, col2 = st.columns(2)
  col1.subheader("Variables num√©riques")
  col2.subheader("Variables cat√©gorielles")
  df2 = df.copy()
  numerics = df2.select_dtypes(include=['int16', 'int32', 'int64', 'float16', 'float32', 'float64']).columns
  categoricals= df2.select_dtypes(include=['object','category']).columns

# variables num√©riques

  tab1, tab2 = col1.tabs(["üìà Chart", "üìã Describe"])
         
  option = tab1.selectbox("Choix une variable num√©rique :",numerics)
  hist = px.histogram(df2,x=option,color="deposit",barmode="group")
  tab1.plotly_chart(hist)
         
  describe= df2[numerics].describe().transpose()
  tab2.write(describe)

  if option=="age":
    col1.info("Les √¢ges extr√™mes semblent avoir une plus forte adh√©rence avec la campagne.")
  elif option=="duration":
    col1.info("On remarque que plus la dur√©e de contact augmente et plus les clients semblent souscrire √† la campagne.")

# variables cat√©gorielles

  tab3, tab4 = col2.tabs(["üìà Chart", "üìã Describe"])

  option = tab3.selectbox("Choix une variable cat√©gorielle :", categoricals)
  hist = px.histogram(df2,y=option,color="deposit",barmode="group")
  tab3.plotly_chart(hist)
         
  describe= df2[categoricals].describe().transpose()
  tab4.write(describe)

  if option=="marital":
    col2.info("Le statut marital 'single' semble rendre plus favorable la campagne.")
  elif option=="housing":
    col2.info("L'absence de pr√™t immo semble augmenter les chances de r√©pondre favorablement √† la campagne.")
  elif option=="month":
    col2.info("On observe que certains mois comme Mars, Septembre et Octobre semblent plus propices  la performance de la campagne."
              "\n A l'inverse les mois de Mai √† Aout semblent diminuer les chances de concr√©tisation. ")
  elif option=="poutcome":
    col2.info("Les clients ayant r√©pondu positivement √† la campagne pr√©c√©dente sont les plus susceptibles de renouveller un d√©p√¥t.")

# ---------- Les correlations -----------

  st.header("Analyse des corr√©lations")
  tab1, tab2 = st.tabs(["‚ñ© Matrice", "üìà Chart"])
         
# Matrice de correlation

  col1, col2 = tab1.columns((2, 1))

  le = LabelEncoder()
  df2=df.copy()
  for col in df2.columns:
    df2[col]= le.fit_transform(df2[col])
  
  fig = plt.figure(figsize=(15,10))
  sns.heatmap(df2.corr(), annot=True, cmap='RdBu_r', center=0)
  col1.pyplot(fig)
  col2.write('')

# Corr√©lations directes

  col3, col4 = tab2.columns((3, 1))

  corr=pd.DataFrame(df2.corr()["deposit"])
  corr=corr.sort_values("deposit",ascending=False, key=abs)
         
  fig = plt.figure(figsize=(10,5))
  df2.corr()['deposit'].sort_values().drop('deposit').plot(kind='bar', cmap='viridis')
  col3.pyplot(fig)

# Corr√©lations coefficients

  coef=df2.corr()["deposit"]
  col4.write(coef)


# ---------- Les observations -----------

  st.header("Observations")
  st.info("""
           On remarque que 8 324 clients n'ont pas √©t√© contact√©s lors de la campagne pr√©c√©dente.
           Lorsque PREVIOUS = 0 alors PDAYS = -1
           """)
  st.info("""
           Dans l'ordre, les variables les plus corr√©l√©es (valeur absolue) avec la target _[deposit]_ sont :
           * **_duration_** = Dur√©e du contact (en secondes)
           * **_contact_** = Type de contact 
           * housing = Pr√™t immo
           * previous = Nb contacts au cours de la campagne pr√©c√©dente
           * housing = pdays = Nb jours √©coul√©s depuis le dernier contact de la campagne pr√©c√©dente
           * previous = balance = Solde compte bancaire
           **Attention** , les **_deux variables_** correspondent √† des donn√©es non connues √† priori (avant lancement de la campagne)
           """)
         
# ______________________________________________________________________________________________________
# 3/ Pr√©processing
# ______________________________________________________________________________________________________

if page==pages[2]: 

  st.title("Pr√©processing - Mod√®les pr√©dictifs")


# ---------- Le pr√©processing, √ßa sert √† quoi -----------

  expander1 = st.expander("Le pr√©processing, √ßa sert √† quoi ?")

  expander1.markdown("""
           Le pr√©processing est une de composante essentielle de la data science.
           Cette √©tape d√©crit toutes les **transformations** effectu√©es sur le jeu de donn√©es initial et indispensables √† la cr√©ation du mod√®le d'apprentissage fiable et robuste.
           Les algorithmes d'apprentissage automatique fonctionnent mieux lorsque les donn√©es sont pr√©sent√©es dans un format qui met en √©vidence les aspects pertinents requis pour r√©soudre un probl√®me.
           Les fonctions de pr√©processing consistent √† **restructurer** les donn√©es brutes sous une forme adapt√©e √† des types particuliers d'algorithmes. Les √©tapes sont :
           * la transformation des donn√©es,
           * la r√©duction des donn√©es,
           * la s√©lection des variables
           * et √† la mise √† l'√©chelle.
           """)
  
  expander1.image('preprocessing.JPG', caption='Les √©tapes de pr√©processing')     


# ---------- Les √©tapes de pr√©processing -----------

  st.header("Les √©tapes de pr√©processing appliqu√©es :")

# Variables num√©riques

  st.subheader("Le traitement des variables num√©riques")
  code = ''' 
    # Creation de tranches d'√¢ges
    df2['t_age'] = pd.cut(x = df2['age'], bins = [17, 30, 40, 50, 65, 96], labels = ['18-30', '30-40','40-50', '50-65','65-95'])

    # Creation de tranches de solde compte bancaire = balance
    df2['t_balance'] = pd.qcut(x=df2["balance"], q=4, labels=[1,2,3,4])

    # Creation de tranches de dur√©e de contact = duration
    df2['t_duration'] = pd.qcut(df2["duration"], q=4, labels=[1,2,3,4])

    # Creation de tranches de dur√©e de contact = duration
    df2['t_duration'] = pd.qcut(df2["duration"], q=4, labels=[1,2,3,4])

    # Creation de tranches de nombre de contact = campaign > Corrige le probl√®me de valeurs abb√©rantes et limite √† 4 contacts
    df2['t_campaign'] = pd.cut(x = df2['campaign'], bins = [0, 1, 2, 3, 99], labels = [1, 2, 3, 4])

    # Cr√©ation d'une cat√©gorie pour contact campagne pr√©c√©dente oui/non
    df2['contact_last_campaign'] = np.where(df2['pdays']>=0, 'yes', 'no')

    # Cr√©ation de tranches en fonction du d√©lai √©coul√©
    df2['t_pdays'] = pd.cut(x = df2['pdays'], bins = [-2, 0, 200, 999], labels = ['NON CONTACTE', 'MOINS DE 200J', 'PLUS DE 200J'])

    # Creation de tranches de nombre de contact avant la campagne
    df2['previous'] = pd.cut(x = df2['previous'], bins = [0, 1, 2, 3, 99], labels = [1, 2, 3, 4])

    # Suppression des colonnes dummies"√©es"
    drop_cols=['age','balance','duration','campaign','pdays','previous']
    df2 = df2.drop(drop_cols, axis=1)
    '''
  st.code(code, language='python')

# Variables cat√©gorielles

  st.subheader("Le traitement des variables cat√©gorielles")
  code = ''' 
    # Cr√©ation de dummies
    var=['marital','education','poutcome','contact','t_age','t_balance','t_duration','t_campaign','t_pdays','month']
    df2= df2.join(pd.get_dummies(df2[var], prefix=var))
    df2 = df2.drop(df2[var], axis=1)

    # Transformation en num√©rique
    le = LabelEncoder()
    df2['job2']= le.fit_transform(df2['job'])
    df2 = df2.drop(['job'], axis=1)

    # Remplace yes/no par 1/0
    var = ["default", "housing","loan","deposit","contact_last_campaign"]
    df2[var] = df2[var].replace(('yes', 'no'), (1, 0))
    '''
  st.code(code, language='python')

         
# ---------- Jeu de donn√©es final -----------

  st.header("Le jeu de donn√©es final :")
  st.write(df2)
         
# ---------- Arbre de correlations apr√®s preprocessing -----------

  st.header("Arbre de correlations apr√®s preprocessing :")

  fig = plt.figure(figsize=(20,8))
  df2.corr()['deposit'].sort_values().drop('deposit').plot(kind='bar', cmap='viridis')
  st.pyplot(fig)

# ---------- Les enseignements -----------

  st.header("Les observations :")
  st.info("""
           On voit clairement que la feature **[duration]** impacte positivement la campagne d√®s lors que la valeur est √©lev√©e (temps de contact). \n
           Egalement, les clients ayant r√©pondu favorablement √† la campagne pr√©c√©dente **[poutcome]** semblent √™tre les plus susceptibles de renouveler leur action. \n
           Les mois de mars et octobre [month] semblent √™tre les meilleurs mois pour optimiser les leads.
           """)


# ______________________________________________________________________________________________________
# 4/ Challenge de mod√®les
# ______________________________________________________________________________________________________

if page==pages[3]:
         
  rlc_accuracy=compare.iloc[0]["Model"]
  st.write(rlc_accuracy)
         
  st.title("Mod√®les pr√©dictifs")
  st.markdown("""
              Les quatre mod√®les pr√©dictifs suivants ont √©t√© choisis en raison de leur √©quilibre entre bonne performance et dur√©e d'ex√©cution sur ce jeu de donn√©es.
              * La **r√©gression logistique** ou RLC
              * Le mod√®le **K-plus proches voisins** ou KNN
              * L'**arbre de d√©cision** ou DTC
              * Les **for√™ts al√©atoires** ou RFC 
              """)
  st.write("  ")

# ---------- Les 3 mod√®les -----------

  col1, col2, col3, col4 = st.columns(4)
         
  # Sauvegarde des r√©sulats de chacun des mod√®les
  models=[]
  scores =[]
  precision=[]
  rappel=[]
  roc=[]
         
# R√©gression logistique -----------------------------------------------------------------------

  with col1:
    st.subheader("Mod√®le RLC")
    st.image("regression-lineaire.png")
         
    #rlc = linear_model.LogisticRegression(C=10)
    #rlc.fit(X_train, y_train)
        
    st.metric("Score train", "{:.2%}".format(rlc.score(X_train, y_train)))
    st.metric("Score test", "{:.2%}".format(rlc.score(X_test, y_test)))
    st.metric("Precision Score", "{:.2%}".format(precision_score(y_test, rlc.predict(X_test))))

    y_pred = rlc.predict(X_test)
    st.write("Matrice de confusion :")
    st.write(pd.crosstab(y_test, y_pred, rownames=['Classe r√©elle'], colnames=['Classe pr√©dite']))

    # Sauvegarde des r√©sultats
    models.append("Regression logistique")
    scores.append(rlc.score(X_test, y_test))
    precision.append(precision_score(y_test, rlc.predict(X_test)))
    rappel.append(recall_score(y_test, rlc.predict(X_test)))
    roc.append(roc_auc_score(y_test, rlc.predict(X_test)))
    probs_rlc = rlc.predict_proba(X_test)
         
# K plus proche voisins -----------------------------------------------------------------------

  with col2:
    st.subheader("Mod√®le KNN")
    st.image("networking.png")

    #knn = neighbors.KNeighborsClassifier(n_neighbors=39)
    #knn.fit(X_train, y_train)
      
    st.metric("Score train", "{:.2%}".format(knn.score(X_train, y_train)))
    st.metric("Score test", "{:.2%}".format(knn.score(X_test, y_test)))
    st.metric("Precision Score", "{:.2%}".format(precision_score(y_test, knn.predict(X_test))))

    y_pred = knn.predict(X_test)
    st.write("Matrice de confusion :")
    st.write(pd.crosstab(y_test, y_pred, rownames=['Classe r√©elle'], colnames=['Classe pr√©dite']))

    # Sauvegarde des r√©sultats
    models.append("K plus proches voisins")
    scores.append(knn.score(X_test, y_test))
    precision.append(precision_score(y_test, knn.predict(X_test)))
    rappel.append(recall_score(y_test, knn.predict(X_test)))
    roc.append(roc_auc_score(y_test, knn.predict(X_test)))
    probs_knn = knn.predict_proba(X_test)
     
# Arbre de d√©cision -----------------------------------------------------------------------

  with col3:
    st.subheader("Mod√®le DTC")
    st.image("arbre-de-decision.png")

    #dtc = tree.DecisionTreeClassifier(max_depth=9)
    #dtc.fit(X_train, y_train)  
        
    st.metric("Score train", "{:.2%}".format(dtc.score(X_train, y_train)))
    st.metric("Score test", "{:.2%}".format(dtc.score(X_test, y_test)))
    st.metric("Precision Score", "{:.2%}".format(precision_score(y_test, dtc.predict(X_test))))

    y_pred = dtc.predict(X_test)
    st.write("Matrice de confusion :")
    st.write(pd.crosstab(y_test, y_pred, rownames=['Classe r√©elle'], colnames=['Classe pr√©dite']))

    # Sauvegarde des r√©sultats
    models.append("Decision Tree")
    scores.append(dtc.score(X_test, y_test))
    precision.append(precision_score(y_test, dtc.predict(X_test)))
    rappel.append(recall_score(y_test, dtc.predict(X_test)))
    roc.append(roc_auc_score(y_test, dtc.predict(X_test)))
    probs_dtc = dtc.predict_proba(X_test)

# Random Forest -----------------------------------------------------------------------

  with col4:
    st.subheader("Mod√®le RFC")
    st.image("foret.png")

    #rfc = ensemble.RandomForestClassifier(n_jobs=1) 
    #rfc.fit(X_train, y_train)
    
    st.metric("Score train", "{:.2%}".format(rfc.score(X_train, y_train)))
    st.metric("Score test", "{:.2%}".format(rfc.score(X_test, y_test)))
    st.metric("Precision Score", "{:.2%}".format(precision_score(y_test, rfc.predict(X_test))))

    y_pred = rfc.predict(X_test)
    st.write("Matrice de confusion :")
    st.write(pd.crosstab(y_test, y_pred, rownames=['Classe r√©elle'], colnames=['Classe pr√©dite']))

    # Sauvegarde des r√©sultats
    models.append("Random Forest")
    scores.append(rfc.score(X_test, y_test))
    precision.append(precision_score(y_test, rfc.predict(X_test)))
    rappel.append(recall_score(y_test, rfc.predict(X_test)))
    roc.append(roc_auc_score(y_test, rfc.predict(X_test)))
    probs_rfc = rfc.predict_proba(X_test)

# Comparaison des r√©sultats -----------------------------------------------------------------------

  st.write(" ")
  
  tab1, tab2 = st.columns(2)

  # Recap des scores
  compare = pd.DataFrame(models)
  compare.columns = ['model']
  compare["accuracy"]=scores
  compare["precision"]=precision
  compare["rappel"]=rappel
  compare["roc"]=roc

  #Graphique de comparaison des r√©sultats
  tab1.subheader("üìä Graphique de comparaison")
  fig = plt.figure(figsize=(20,6))
  bar = px.bar(compare, x="model", y=['accuracy', 'precision', 'rappel','roc'], barmode='group')
  bar.add_hline(y=0.80, line_width=3, line_dash="dash", line_color="black")
  tab1.plotly_chart(bar)     

  # Comparaison avec l'indice des ROC
  tab2.subheader("üìà Courbe ROC")

  # Regression logistique
  fpr_rlc, tpr_rlc, seuils = roc_curve(y_test, probs_rlc[:,1])
  roc_auc_rlc = auc(fpr_rlc, tpr_rlc)

  # K plus proches voisins
  fpr_knn, tpr_knn, seuils = roc_curve(y_test, probs_knn[:,1])
  roc_auc_knn = auc(fpr_knn, tpr_knn)

  # Decision Tree
  fpr_dtc, tpr_dtc, seuils = roc_curve(y_test, probs_dtc[:,1])
  roc_auc_dtc = auc(fpr_dtc, tpr_dtc)

  # Random Forest
  fpr_rfc, tpr_rfc, seuils = roc_curve(y_test, probs_rfc[:,1])
  roc_auc_rfc = auc(fpr_rfc, tpr_rfc)

  # Les courbes
  import plotly.graph_objects as go         
  fig = go.Figure(data=go.Scatter(x=fpr_rlc, y=tpr_rlc , mode='lines', name='Mod√®le RLC (auc = %0.2f)' % roc_auc_rlc))
  fig.add_trace(go.Scatter(x=fpr_knn, y=tpr_knn , mode='lines', name='Mod√®le KNN (auc = %0.2f)' % roc_auc_knn))
  fig.add_trace(go.Scatter(x=fpr_dtc, y=tpr_dtc , mode='lines', name='Mod√®le DTC (auc = %0.2f)' % roc_auc_dtc))
  fig.add_trace(go.Scatter(x=fpr_rfc, y=tpr_rfc , mode='lines', name='Mod√®le RFC (auc = %0.2f)' % roc_auc_rfc))
  fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], name='Al√©atoire (auc = 0.5)', line = dict(color='black', width=2, dash='dot')))
  fig.update_layout(height=450, width=700, legend=dict(yanchor="top", y=0.5, xanchor="left", x=0.65))
  tab2.plotly_chart(fig)          
         
  with tab2.expander("Plus d'explication sur ce graphique :"):
    st.write("""
         La courbe ROC (pour **Receiver Operating Characteristic**) est une courbe qui repr√©sente le comportement de notre classifieur √† deux classes pour tous les seuils de d√©tection possibles.
         \n Si nous utilisons les probabilit√©s d‚Äôappartenance √† la classe cible renvoy√©es par notre classifieur au lieu des pr√©dictions,
         nous pourrions choisir librement √† partir de quelle probabilit√© nous consid√©rons qu‚Äôun item est de cette classe.
         \n En prenant des seuils de 0 √† 1 (ou 100%), nous balayons **toutes les possibilit√©s**.
         \n A chaque seuil, nous pouvons calculer le taux de vrais positifs et le taux de faux positifs.
         \n La courbe ROC repr√©sente ces r√©sultats avec le taux de faux positifs sur l‚Äôaxe x et le taux de vrais positifs sur l‚Äôaxe y.
     """)

  st.subheader("üèÜ Le mod√®le gagnant")
  st.success("Le mod√®le **Random Forest** obtient les meilleures performances et semble le plus √©quilibr√©. Il permet de maximiser les positifs.")

         
         
# ______________________________________________________________________________________________________
# 5/ BONUS
# ______________________________________________________________________________________________________

if page==pages[5]: 

  st.title("‚öôÔ∏è Personnaliser votre campagne")
  st.write(" ")
  st.write(" ")

  col1, col2, col3, col4, col5  = st.columns((1, 2 , 1, 2, 1))

# Volet personnalisation de la campagne -----------------------------------------------------------------------

  model = col2.radio(
     "‚ú®Quel mod√®le pr√©dictif souhaitez-vous privil√©gier ?",
     ('R√©gression logistique', 'K-Plus proches voisins', 'Arbre de d√©cisions', 'F√¥rets al√©atoires'), index=3)
  
  seuil = col2.number_input(
      "üéöÔ∏è Quel seuil pour les pr√©dictions ?", min_value=0.1, max_value=0.9, value=0.5)         
         
  m = col4.select_slider(
     'üìÖ Quel est le mois pr√©visionnel de lancement de cette nouvelle campagne ?',
     options=['Janvier', 'F√©vrier','Mars', 'Avril', 'Mai','Juin', 'Juillet', 'Ao√ªt', 'Septembre','Octobre', 'Novembre','D√©cembre'])
         
  d = col4.select_slider(
     "‚åö A combien de minutes estimez-vous la dur√©e d'un appel t√©l√©phonique pour cette campagne ?",
     options=["1:00", "2:00", "3:00", "4:00", "5:00", "6:00", "7:00", "8:00", "9:00", "10:00"], value="5:00")
   
  st.write(" ")

# Volet entrainement du mod√®le de la campagne -----------------------------------------------------------------------

  col6, col7, col8  = st.columns(3)

  if col7.button('Lancer la pr√©diction'): 
    feats_modif_x=feats_modif.copy()

    # Choix du mod√®le -----------------------------------
    if model == "R√©gression logistique":
      classifieur = rlc
    elif model == "K-Plus proches voisins":
      classifieur = knn
    elif model == "Arbre de d√©cisions":
      classifieur = dtc
    else:
      classifieur = rfc

    # Choix du mois -----------------------------------
    if m == "Janvier":
      feats_modif_x["month_jan"]=1
    elif m == "F√©vrier":
      feats_modif_x["month_feb"]=1
    elif m == "Mars":
      feats_modif_x["month_mar"]=1
    elif m == "Avril":
      feats_modif_x["month_apr"]=1
    elif m == "Mai":
      feats_modif_x["month_may"]=1
    elif m == "Juin":
      feats_modif_x["month_jun"]=1
    elif m == "Juillet":
      feats_modif_x["month_jul"]=1
    elif m == "Ao√ªt":
      feats_modif_x["month_aug"]=1
    elif m == "Septembre":
      feats_modif_x["month_sep"]=1
    elif m == "Octobre":
      feats_modif_x["month_oct"]=1
    elif m == "Novembre":
      feats_modif_x["month_nov"]=1
    else:
      feats_modif_x["month_dec"]=1

    # Choix de la dur√©e -----------------------------------
    if d in ["1:00","2:00"]:
      feats_modif_x["t_duration_1"]=1
    elif d in ["3:00","4:00"]:
      feats_modif_x["t_duration_2"]=1    
    elif d in ["4:00","5:00","6:00","7:00"]:
      feats_modif_x["t_duration_3"]=1                  
    else:
      feats_modif_x["t_duration_4"]=1    

    # Entrainement du mod√®le choisi -----------------------------------
         
    col7.write(classifieur)
    col7.write(" ")  
         
    y_pred = classifieur.predict(feats_modif_x)
    probas=classifieur.predict_proba(feats_modif_x)
    probas=pd.DataFrame(probas, columns=['NO','Probabilit√©s'], index=feats_modif_x.index)
    probas = probas.drop(['NO'], axis=1)
    probas['Classification'] = np.where(probas['Probabilit√©s']>seuil,1,0)         

    col9, col10, col11  = st.columns(3)

    col9.write(" ")
    col9.write(" ") 
    col9.write(" ") 
    col9.subheader("Distribution des probabilit√©s")
    fig = px.histogram(probas,x="Probabilit√©s",color="Classification", nbins=100)
    fig.add_vline(x=seuil, line_width=3, line_dash="dash", line_color="black")
    fig.update_layout(height=400, width=500, legend=dict(yanchor="top", y=0.8, xanchor="left", x=0.8))
    col9.plotly_chart(fig) 
         
    col10.write(" ")
    col10.write(" ") 
    col10.write(" ") 
    col10.subheader("R√©partition des pr√©dictions")
    pie = px.pie(probas, values='Probabilit√©s', names='Classification', hole=.3)
    pie.update_layout(height=400, width=400, legend=dict(yanchor="top", y=0.8, xanchor="left", x=0.8))
    col10.plotly_chart(pie)

    col11.write(" ")
    col11.write(" ") 
    col11.write(" ") 
    col11.subheader("Chiffres cl√©s")
    col11.metric("Performance pr√©sum√©e de la campagne *", "70 ¬∞F", "1.2 ¬∞F")
    col11.metric("Nombre de clients scor√©s positifs", "9 mph", "-8%")
    col11.metric("Score du mod√®le **", "86%", "4%")
         
    st.write(" ") 
    st.write("*Performance : Pourcentage estim√© de clients susceptibles d'effectuer un d√©p√¥t lors de la campagne.") 
    st.write("*Score du mod√®le : Mesure du taux de pr√©dictions correctes effectu√©es par le mod√®le utilis√©. Le mod√®le Random Forest est utilis√© comme r√©f√©rence.") 
